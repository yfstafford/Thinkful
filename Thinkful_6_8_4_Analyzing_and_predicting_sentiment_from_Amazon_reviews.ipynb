{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thinkful 6.8.4 Analyzing and predicting sentiment from Amazon reviews.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yfstafford/Thinkful/blob/master/Thinkful_6_8_4_Analyzing_and_predicting_sentiment_from_Amazon_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0NM9iEXca5W",
        "colab_type": "text"
      },
      "source": [
        "Now that you've looked at an example of how we can use Spark in batch mode, it's time to try it out on your own.\n",
        "\n",
        "In this challenge you'll revisit the sentiment analysis we did earlier in the course - specifically, the Amazon reviews dataset. You should choose one of the 5-core datasets. Keep in mind that if the data is g-zipped, you'll need to unpack the dataset before you use it.\n",
        "\n",
        "You should complete this challenge in a Jupyter notebook, which will need to work on Colab.\n",
        "\n",
        "Now, on to the task at hand!\n",
        "\n",
        "It's always important to start with a clear goal in mind. In this case, we'd like to determine if we can predict whether a review is positive or negative based on the language in the review.\n",
        "\n",
        "We're going to tackle this problem with Spark, so you'll need to apply the principles you've learned thus far in the context of Spark.\n",
        "\n",
        "Some tips to help you get started:\n",
        "\n",
        "- Pyspark always needs to point at a running Spark instance. You can do that using a SparkContext.\n",
        "- We're still working in batch mode, so you'll need to load an entire file into memory in order to run any models you build.\n",
        "- Spark likes to execute models in a pipeline, so remember that when the time comes to set up your model.\n",
        "- Spark's machine learning algorithms expect numeric variables.\n",
        "\n",
        "When you're done, save your notebook and push it up to GitHub. Submit a link to your notebook below.\n",
        "\n",
        "After submitting your work, review the example solution provided in your big data student resources directory - examples/Amazon Reviews Exercise.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLqGBgCM7s8h",
        "colab_type": "text"
      },
      "source": [
        "## Spark and Colaboratory setup\n",
        "\n",
        "First, there's some configration specific to running Spark on Colaboratory that we'll need to attend to. Run these cells to set everything up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ahlaHUHYnGcg",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWBTMZhE7s8l",
        "colab_type": "code",
        "outputId": "927b8cd0-22fc-4810-b3c9-80bdd8c0fc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "# Install spark-related depdencies for Python\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 176kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 34.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=8915f5951516aa74dc81971d840c3c20c06cce570215554c159338650c413bfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9pxKUb5pnHix",
        "colab": {}
      },
      "source": [
        "# Set up required environment variables\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xo-SbYg7s8p",
        "colab_type": "code",
        "outputId": "74195e1f-0cb3-4a96-88c5-383c6bea686d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "# Point Colaboratory to Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cTDxREFdlx11"
      },
      "source": [
        "##  Import dependencies\n",
        "\n",
        "Next, we need to import the tools we'll need from PySpark. The imports below allow us to connect to the Spark server, load our data, clean it, and prepare, execute, and evaluate a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBIeh7Eblx12",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext, SQLContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import GBTClassifier, LinearSVC, LogisticRegression\n",
        "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler, Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import functools\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5PLkpx0slx15"
      },
      "source": [
        "## Set our constants\n",
        "\n",
        "Next, we create a set of constants that we can refer to throughout the notebook. These are values that the rest of our code needs to run, but that we might need to change at some point (for instance, if the location of our data changes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mqs6LIRelx16",
        "colab": {}
      },
      "source": [
        "DATA_PATH = \"/content/gdrive/My Drive/Colab Datasets/Kindle_Store_5.json\" \n",
        "APP_NAME = \"Kindle Review Sentiment\"\n",
        "SPARK_URL = \"local[*]\"\n",
        "RANDOM_SEED = 47\n",
        "TRAINING_DATA_RATIO = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hh1r-3Ialx19"
      },
      "source": [
        "## Connect to the server and load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-26_dwoUVzq",
        "colab_type": "text"
      },
      "source": [
        "Data are stored in a JSON format file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e3daglotlx19",
        "colab": {}
      },
      "source": [
        "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuzYzXULjWjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df0 = spark.read.options(inferschema = \"true\").json(DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I-Nvc64dwcR",
        "colab_type": "code",
        "outputId": "8fc257be-d03f-4cd5-9f4c-e65fca025e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "df0.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(asin='B000F83SZQ', helpful=[0, 0], overall=5.0, reviewText=\"I enjoy vintage books and movies so I enjoyed reading this book.  The plot was unusual.  Don't think killing someone in self-defense but leaving the scene and the body without notifying the police or hitting someone in the jaw to knock them out would wash today.Still it was a good read for me.\", reviewTime='05 5, 2014', reviewerID='A1F6404F1VG29J', reviewerName='Avidreader', summary='Nice vintage story', unixReviewTime=1399248000),\n",
              " Row(asin='B000F83SZQ', helpful=[2, 2], overall=4.0, reviewText=\"This book is a reissue of an old one; the author was born in 1910. It's of the era of, say, Nero Wolfe. The introduction was quite interesting, explaining who the author was and why he's been forgotten; I'd never heard of him.The language is a little dated at times, like calling a gun a &#34;heater.&#34;  I also made good use of my Fire's dictionary to look up words like &#34;deshabille&#34; and &#34;Canarsie.&#34; Still, it was well worth a look-see.\", reviewTime='01 6, 2014', reviewerID='AN0N05A9LIJEQ', reviewerName='critters', summary='Different...', unixReviewTime=1388966400),\n",
              " Row(asin='B000F83SZQ', helpful=[2, 2], overall=4.0, reviewText=\"This was a fairly interesting read.  It had old- style terminology.I was glad to get  to read a story that doesn't have coarse, crasslanguage.  I read for fun and relaxation......I like the free ebooksbecause I can check out a writer and decide if they are intriguing,innovative, and have enough of the command of Englishthat they can convey the story without crude language.\", reviewTime='04 4, 2014', reviewerID='A795DMNCJILA6', reviewerName='dot', summary='Oldie', unixReviewTime=1396569600),\n",
              " Row(asin='B000F83SZQ', helpful=[1, 1], overall=5.0, reviewText=\"I'd never read any of the Amy Brewster mysteries until this one..  So I am really hooked on them now.\", reviewTime='02 19, 2014', reviewerID='A1FV0SX13TWVXQ', reviewerName='Elaine H. Turley \"Montana Songbird\"', summary='I really liked it.', unixReviewTime=1392768000),\n",
              " Row(asin='B000F83SZQ', helpful=[0, 1], overall=4.0, reviewText='If you like period pieces - clothing, lingo, you will enjoy this mystery.  Author had me guessing at least 2/3 of the way through.', reviewTime='03 19, 2014', reviewerID='A3SPTOKDG7WBLN', reviewerName='Father Dowling Fan', summary='Period Mystery', unixReviewTime=1395187200)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c-r3VQzLlx2A"
      },
      "source": [
        "## Clean and preprocess the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTWxdGVhUed0",
        "colab_type": "text"
      },
      "source": [
        "Due to the size of the data set and memory constraints, only a sample of the full data set will be analyzed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iokDZIFRlx2A",
        "outputId": "e9f18242-0c66-436d-dec8-23d8defe3e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(f\"Dataset shape is {df0.count():d} rows by {len(df0.columns):d} columns.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape is 982619 rows by 9 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e7eTv5AMdtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take subsample to reduce RAM load\n",
        "(df0, df1) = df0.randomSplit([0.05, 0.95], seed=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kETc_W1hMuMA",
        "colab_type": "code",
        "outputId": "22c331fc-e7e2-4b35-d966-a7a074b1261d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(f\"Dataset shape is {df0.count():d} rows by {len(df0.columns):d} columns.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape is 49281 rows by 9 columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zh9sVIqtlx2E",
        "outputId": "17ee5b61-4931-4635-eb58-2030dfc8c9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "df0.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('asin', 'string'),\n",
              " ('helpful', 'array<bigint>'),\n",
              " ('overall', 'double'),\n",
              " ('reviewText', 'string'),\n",
              " ('reviewTime', 'string'),\n",
              " ('reviewerID', 'string'),\n",
              " ('reviewerName', 'string'),\n",
              " ('summary', 'string'),\n",
              " ('unixReviewTime', 'bigint')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDjjQN0qUmzn",
        "colab_type": "text"
      },
      "source": [
        "Reviews will be designated as positive or negative with reviews > 3 as positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g9H73yfmFOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df0 = df0.withColumn('positive',(df0['overall'] > 3).cast('double'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-cdWWWcS-zd",
        "colab_type": "code",
        "outputId": "5167fc33-a1ad-49d7-90ed-41b60137e251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "group_counts = df0.groupBy('positive').count().collect()\n",
        "\n",
        "is_positive = [ c[0] for c in group_counts ]\n",
        "counts = [ c[1] for c in group_counts ]\n",
        " \n",
        "ax = np.array(range(len(is_positive)))\n",
        "width = 0.25\n",
        "plt.bar(ax, counts, width=width, color='r')\n",
        "\n",
        "plt.xlabel('Positive?')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Sentiment Distribution')\n",
        "plt.xticks(ax + width/2., is_positive)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7fc94bf35e80>,\n",
              "  <matplotlib.axis.XTick at 0x7fc94bf35b70>],\n",
              " <a list of 2 Text xticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HflZfccOVP6o",
        "colab_type": "text"
      },
      "source": [
        "There is a group imbalance so measures such as accuracy may not be appropriate for this data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttYgVMNNU2L1",
        "colab_type": "text"
      },
      "source": [
        "NLP processing will use tf-idf matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G0KoiO5mV4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"tokenized\").transform(df0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd1fufnWOdIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf-idf processing\n",
        "hashingTF = HashingTF(inputCol=\"tokenized\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "featurizedData = hashingTF.transform(tokenizer)\n",
        " \n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "idfModel = idf.fit(featurizedData)\n",
        "df = idfModel.transform(featurizedData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjRUUls6tJpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.select(['positive','features'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R293gzHvVHx4",
        "colab_type": "text"
      },
      "source": [
        "Training indexers are needed for running models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-eNWl6FppSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate labelIndexer\n",
        "labelIndexer = StringIndexer(inputCol=\"positive\", outputCol=\"label\").fit(df)\n",
        "df = labelIndexer.transform(df)\n",
        "\n",
        "df = df.select(['features','label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prlZ4SdpVT5e",
        "colab_type": "text"
      },
      "source": [
        "Data are split into training/test sets with 20% held out for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhDUfzrdpqJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainingData, testData) = df.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO], seed=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM8OhutvbmFu",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosted Tree Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ-hVjm4VsEN",
        "colab_type": "text"
      },
      "source": [
        "By repeatedly passing residual data from a decision tree model to the next, gradient boosted tree models can generate good results, even if the relationship between variables is fairly weak."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bayuf5sGbwLB",
        "colab": {}
      },
      "source": [
        "# Train a Gradient Boosted model.\n",
        "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=15)\n",
        "model = gbt.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MRepZPxgbwLE",
        "colab": {}
      },
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YCruLwCS1J6",
        "colab_type": "text"
      },
      "source": [
        "The data set is imbalanced so rather than using accuracy, area under the ROC curve will be used to compare models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmSD2NWul4Uj",
        "colab_type": "code",
        "outputId": "8724969d-54d8-4a72-c75b-33d58f44c788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Calculate area under ROC curve\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print('Test Area Under ROC', evaluator.evaluate(predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Area Under ROC 0.7965709478422993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d941bfca-41ae-4122-ffd8-fb8cdd48f639",
        "id": "sTtJty0DbwLL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "predictions.groupBy('label','prediction').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|  120|\n",
            "|  0.0|       1.0|   74|\n",
            "|  1.0|       0.0| 1396|\n",
            "|  0.0|       0.0| 8340|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HH_hSgBndHgA"
      },
      "source": [
        "## LinearSVC Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7CQ2j90ZC6w",
        "colab_type": "text"
      },
      "source": [
        "LinearSVC is relatively light in terms of resource requirements and so might be worth checking in a large data set such as this one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJ_B8XY9dHgD",
        "colab": {}
      },
      "source": [
        "# Train a LinearSVC model.\n",
        "svc = LinearSVC(labelCol=\"label\", featuresCol=\"features\",maxIter=20)\n",
        "model = svc.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNuK_S75dHgF",
        "colab": {}
      },
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cd65ccc5-1bcd-41f4-cf91-c8b890f98333",
        "id": "m8paWIGhdHgI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Calculate area under ROC curve\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print('Test Area Under ROC', evaluator.evaluate(predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Area Under ROC 0.8568179808373149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f89b2449-083a-4037-c6a6-896d76e8f967",
        "id": "Ra03yY6cdHgK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "predictions.groupBy('label','prediction').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|  233|\n",
            "|  0.0|       1.0|   90|\n",
            "|  1.0|       0.0| 1283|\n",
            "|  0.0|       0.0| 8324|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kt902_pgGIzA"
      },
      "source": [
        "## Ridge Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOw1-feaXsY_",
        "colab_type": "text"
      },
      "source": [
        "Ridge regression allows for regularization and can be used to reduce the weight of less important features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "07IYNCg3GIzD",
        "colab": {}
      },
      "source": [
        "# Train a Ridge regression model.\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\",maxIter=20,regParam=0.01)\n",
        "model = lr.fit(trainingData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "45SCuF3TGIzG",
        "colab": {}
      },
      "source": [
        "# Make predictions.\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2b151a0e-2846-42d3-f25d-bcb7128dadca",
        "id": "xbIy6i_5GIzJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Calculate area under ROC curve\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print('Test Area Under ROC', evaluator.evaluate(predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Area Under ROC 0.8606380213151472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7ea86dd3-7f50-43fe-c307-2b72f0979944",
        "id": "Hxh1s4k5GIzM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "predictions.groupBy('label','prediction').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|  461|\n",
            "|  0.0|       1.0|  212|\n",
            "|  1.0|       0.0| 1055|\n",
            "|  0.0|       0.0| 8202|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI4y42vlQS4c",
        "colab_type": "text"
      },
      "source": [
        "## Optimize Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62fVizX4TIMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainingData2, testData2) = df0.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO], seed=RANDOM_SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ipgZagQTUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure an ML pipeline, which consists of five stages: tokenizer, hashingTF, IDF, li2, and lr.\n",
        "tokenizer2 = Tokenizer(inputCol='reviewText', outputCol='tokenized')\n",
        "hashingTF2 = HashingTF(inputCol='tokenized', outputCol='rawFeatures')\n",
        "idf2 = IDF(inputCol=\"rawFeatures\", outputCol=\"tfidf\")\n",
        "\n",
        "# Generate labelIndexer\n",
        "li2 = StringIndexer(inputCol=\"positive\", outputCol=\"label\")\n",
        "\n",
        "lr2 = LogisticRegression(labelCol=\"label\", featuresCol=\"tfidf\",maxIter=20)\n",
        "pipeline2 = Pipeline(stages=[tokenizer2, hashingTF2, idf2, li2, lr2])\n",
        "\n",
        "# Use a ParamGridBuilder in conjunction with a CrossValidator to perform a parameter grid search\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(hashingTF2.numFeatures, [1000, 1500, 2000]) \\\n",
        "    .addGrid(lr2.regParam, [0.04, 0.02, 0]) \\\n",
        "    .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=pipeline2,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=BinaryClassificationEvaluator(),\n",
        "                          numFolds=4,            \n",
        "                          collectSubModels=True)\n",
        "\n",
        "# Run cross-validation, and choose the best set of parameters.\n",
        "cvModel = crossval.fit(trainingData2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AXE1FKY2Cc",
        "colab_type": "code",
        "outputId": "b41ba46c-86f8-4a41-bee4-a5f694421ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Find optimal parameters\n",
        "cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='HashingTF_47e2bf9c09fe', name='numFeatures', doc='number of features.'): 2000,\n",
              " Param(parent='LogisticRegression_3585af9ebc42', name='regParam', doc='regularization parameter (>= 0).'): 0.04}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk9ho5PTP_Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions\n",
        "predictions = cvModel.transform(testData2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obYVihiEnvRA",
        "colab_type": "code",
        "outputId": "48cacf22-0187-497f-925a-a697976b0d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Calculate area under ROC curve\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "print('Test Area Under ROC', evaluator.evaluate(predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Area Under ROC 0.8598129552311594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db8f1f2c-04bf-42f4-c99d-f7ea159316ee",
        "id": "roeepywCRdKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "predictions.groupBy('label','prediction').count().show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|  1.0|       1.0|  423|\n",
            "|  0.0|       1.0|  141|\n",
            "|  1.0|       0.0| 1147|\n",
            "|  0.0|       0.0| 8219|\n",
            "+-----+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1_1G3UDxAuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}