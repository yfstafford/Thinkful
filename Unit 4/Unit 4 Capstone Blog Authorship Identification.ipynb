{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Blog Author Identification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv('../data/blogtext.csv', delimiter=',',usecols=['id','topic','date','text'])\n",
    "df0.dataframeName = 'blogtext.csv'\n",
    "nRow, nCol = df0.shape\n",
    "print(f'There are {nRow} total blog entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.drop_duplicates(subset=\"text\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove blogs using non-English months in their date fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_strings = df0['date'].str.title()\n",
    "english_month = (date_strings.str.contains(',January,')) | (date_strings.str.contains(',February,')) | \\\n",
    "               (date_strings.str.contains(',March,')) | (date_strings.str.contains(',April,')) | \\\n",
    "               (date_strings.str.contains(',May,')) | (date_strings.str.contains(',June,')) | \\\n",
    "               (date_strings.str.contains(',July,')) | (date_strings.str.contains(',August,')) | \\\n",
    "               (date_strings.str.contains(',September,')) | (date_strings.str.contains(',October,')) | \\\n",
    "               (date_strings.str.contains(',November,')) | (date_strings.str.contains(',December,'))\n",
    "df = df0.drop(df0[~english_month].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['date'].str.title(), format='%d,%B,%Y')\n",
    "df = df.drop(columns=['date'])\n",
    "nRow, nCol = df.shape\n",
    "print(f'After filtering for English months, there are {nRow} remaining blog entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter blog entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of posts by author and topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_count = df.groupby('id').size()\n",
    "df['post_count'] = [ post_count[id] for id in df['id'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_count = df.groupby('topic').size()\n",
    "df['topic_count'] = [ topic_count[topic] for topic in df['topic'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most heavily posted topic is 'Student' so focus on those posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['topic'] == 'Student']\n",
    "df.groupby('id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only authors with at least 500 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['post_count'] >= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15 remaining authors with a total of 15,301 posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['topic','datetime','post_count','topic_count'])\n",
    "#df.to_csv('reduced_blog_corpus.csv')\n",
    "\n",
    "del df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training/test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],df['id'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process posts with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (96) into shape (128)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"<ipython-input-1-44bcee7fcd2b>\"\u001b[0m, line \u001b[0;32m7\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    nlp = spacy.load('en')\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\"\u001b[0m, line \u001b[0;32m15\u001b[0m, in \u001b[0;35mload\u001b[0m\n    return util.load_model(name, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m112\u001b[0m, in \u001b[0;35mload_model\u001b[0m\n    return load_model_from_link(name, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m129\u001b[0m, in \u001b[0;35mload_model_from_link\u001b[0m\n    return cls.load(**overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\\__init__.py\"\u001b[0m, line \u001b[0;32m12\u001b[0m, in \u001b[0;35mload\u001b[0m\n    return load_model_from_init_py(__file__, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m173\u001b[0m, in \u001b[0;35mload_model_from_init_py\u001b[0m\n    return load_model_from_path(data_path, meta, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m156\u001b[0m, in \u001b[0;35mload_model_from_path\u001b[0m\n    return nlp.from_disk(model_path)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\language.py\"\u001b[0m, line \u001b[0;32m653\u001b[0m, in \u001b[0;35mfrom_disk\u001b[0m\n    util.from_disk(path, deserializers, exclude)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m511\u001b[0m, in \u001b[0;35mfrom_disk\u001b[0m\n    reader(path / key)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\language.py\"\u001b[0m, line \u001b[0;32m649\u001b[0m, in \u001b[0;35m<lambda>\u001b[0m\n    deserializers[name] = lambda p, proc=proc: proc.from_disk(p, vocab=False)\n",
      "  File \u001b[0;32m\"pipeline.pyx\"\u001b[0m, line \u001b[0;32m643\u001b[0m, in \u001b[0;35mspacy.pipeline.Tagger.from_disk\u001b[0m\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m511\u001b[0m, in \u001b[0;35mfrom_disk\u001b[0m\n    reader(path / key)\n",
      "  File \u001b[0;32m\"pipeline.pyx\"\u001b[0m, line \u001b[0;32m626\u001b[0m, in \u001b[0;35mspacy.pipeline.Tagger.from_disk.load_model\u001b[0m\n",
      "  File \u001b[0;32m\"pipeline.pyx\"\u001b[0m, line \u001b[0;32m627\u001b[0m, in \u001b[0;35mspacy.pipeline.Tagger.from_disk.load_model\u001b[0m\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\model.py\"\u001b[0m, line \u001b[0;32m352\u001b[0m, in \u001b[0;35mfrom_bytes\u001b[0m\n    copy_array(dest, param[b'value'])\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\thinc\\neural\\util.py\"\u001b[1;36m, line \u001b[1;32m48\u001b[1;36m, in \u001b[1;35mcopy_array\u001b[1;36m\u001b[0m\n\u001b[1;33m    dst[:] = src\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m could not broadcast input array from shape (96) into shape (128)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Get spaCy stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = list(spacy.lang.en.stop_words.STOP_WORDS)\n",
    "\n",
    "# Initialize English parser\n",
    "parser = English()\n",
    "\n",
    "# Create spaCy tokenizer\n",
    "def spacy_tokenizer(sentence):\n",
    "    \n",
    "    # Create tokens object from parser\n",
    "    tokens = parser(sentence)\n",
    "\n",
    "    # Remove words not included in NLP vocab list (oov = out of vocabulary)\n",
    "    tokens = [ t for t in tokens if t.is_oov is False ]\n",
    "    \n",
    "    # Exclusion list\n",
    "    exclusion_list = list(string.punctuation)\n",
    "    exclusion_list.extend(list(stop_words))\n",
    "    \n",
    "    # Lemmatize, convert to lowercase and remove extra spaces\n",
    "    tokens = [ w.lemma_.strip().lower() for w in tokens if w.lemma_ not in exclusion_list ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (96) into shape (128)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"<ipython-input-1-cd38177bd774>\"\u001b[0m, line \u001b[0;32m3\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    nlp = spacy.load('en')\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\"\u001b[0m, line \u001b[0;32m15\u001b[0m, in \u001b[0;35mload\u001b[0m\n    return util.load_model(name, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m112\u001b[0m, in \u001b[0;35mload_model\u001b[0m\n    return load_model_from_link(name, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m129\u001b[0m, in \u001b[0;35mload_model_from_link\u001b[0m\n    return cls.load(**overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\data\\en\\__init__.py\"\u001b[0m, line \u001b[0;32m12\u001b[0m, in \u001b[0;35mload\u001b[0m\n    return load_model_from_init_py(__file__, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m173\u001b[0m, in \u001b[0;35mload_model_from_init_py\u001b[0m\n    return load_model_from_path(data_path, meta, **overrides)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m156\u001b[0m, in \u001b[0;35mload_model_from_path\u001b[0m\n    return nlp.from_disk(model_path)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\language.py\"\u001b[0m, line \u001b[0;32m653\u001b[0m, in \u001b[0;35mfrom_disk\u001b[0m\n    util.from_disk(path, deserializers, exclude)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m511\u001b[0m, in \u001b[0;35mfrom_disk\u001b[0m\n    reader(path / key)\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\language.py\"\u001b[0m, line \u001b[0;32m649\u001b[0m, in \u001b[0;35m<lambda>\u001b[0m\n    deserializers[name] = lambda p, proc=proc: proc.from_disk(p, vocab=False)\n",
      "  File \u001b[0;32m\"pipeline.pyx\"\u001b[0m, line \u001b[0;32m643\u001b[0m, in \u001b[0;35mspacy.pipeline.Tagger.from_disk\u001b[0m\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\spacy\\util.py\"\u001b[0m, line \u001b[0;32m511\u001b[0m, in \u001b[0;35mfrom_disk\u001b[0m\n    reader(path / key)\n",
      "  File \u001b[0;32m\"pipeline.pyx\"\u001b[0m, line \u001b[0;32m626\u001b[0m, in \u001b[0;35mspacy.pipeline.Tagger.from_disk.load_model\u001b[0m\n",
      "  File \u001b[0;32m\"pipeline.pyx\"\u001b[0m, line \u001b[0;32m627\u001b[0m, in \u001b[0;35mspacy.pipeline.Tagger.from_disk.load_model\u001b[0m\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\thinc\\neural\\_classes\\model.py\"\u001b[0m, line \u001b[0;32m352\u001b[0m, in \u001b[0;35mfrom_bytes\u001b[0m\n    copy_array(dest, param[b'value'])\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\thinc\\neural\\util.py\"\u001b[1;36m, line \u001b[1;32m48\u001b[1;36m, in \u001b[1;35mcopy_array\u001b[1;36m\u001b[0m\n\u001b[1;33m    dst[:] = src\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m could not broadcast input array from shape (96) into shape (128)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "doc = nlp('I am sflmgmavknsaccasas dog cat bird bulbasaur')\n",
    "\n",
    "for token in tokens: \n",
    "    # Printing the following attributes of each token. \n",
    "    # text: the word string, has_vector: if it contains \n",
    "    # a vector representation in the model,  \n",
    "    # vector_norm: the algebraic norm of the vector, \n",
    "    # is_oov: if the word is out of vocabulary. \n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_out = bow_vector.fit_transform(X_train)\n",
    "bow_test_out = bow_vector.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dimensions of the BoW training set are: ' + str(bow_train_out.shape))\n",
    "print('The dimensions of the BoW test set are: ' + str(bow_test_out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "bow_train_out = normalize(bow_train_out)\n",
    "bow_test_out = normalize(bow_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_out = tfidf_vector.fit_transform(X_train)\n",
    "tfidf_test_out = tfidf_vector.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dimensions of the tf-idf training set are: ' + str(tfidf_train_out.shape))\n",
    "print('The dimensions of the tf-idf test set are: ' + str(tfidf_test_out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_out = normalize(tfidf_train_out)\n",
    "tfidf_test_out = normalize(tfidf_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_svd = TruncatedSVD(1000)\n",
    "bow_train_lsa = bow_svd.fit_transform(bow_train_out)\n",
    "\n",
    "variance_explained = bow_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance of BoW training set captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_svd = TruncatedSVD(500)\n",
    "bow_test_lsa = bow_svd.fit_transform(bow_test_out)\n",
    "\n",
    "variance_explained=bow_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance of BoW test captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_svd= TruncatedSVD(1000)\n",
    "tfidf_train_lsa = tfidf_svd.fit_transform(tfidf_train_out)\n",
    "\n",
    "variance_explained=tfidf_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance tf-idf training captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_svd= TruncatedSVD(500)\n",
    "tfidf_test_lsa = tfidf_svd.fit_transform(tfidf_test_out)\n",
    "\n",
    "variance_explained=tfidf_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance tf-idf test captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Initialize and fit K-Means\n",
    "bow_full_pred = KMeans(n_clusters=15, random_state=42).fit_predict(bow_train_out)\n",
    "\n",
    "# Check actual vs. predicted\n",
    "pd.crosstab(Y_train, bow_full_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Initialize and fit Mini-Batch K-Means\n",
    "minibatchkmeans = MiniBatchKMeans(init='random', n_clusters=15, batch_size=1000)\n",
    "minibatchkmeans.fit(bow_train_out)\n",
    "\n",
    "predict_mini = minibatchkmeans.predict(bow_train_out)\n",
    "\n",
    "# Check the Mini-Batch model against our earlier one\n",
    "print('Comparing K-Means and Mini-Batch K-Means solutions:')\n",
    "print(pd.crosstab(predict_mini, bow_full_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-Batch runs much faster than a full K-Means and for most bloggers, the majority of results are consistent. However, there are some exceptions that are split fairly evenly between a couple of buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "    \n",
    "bow_kmeans_ari = metrics.adjusted_rand_score(Y_train, bow_full_pred)\n",
    "bow_kmeans_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), bow_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for K-Means BoW is: ' + str(bow_kmeans_ari))\n",
    "print('Silhouette score for K-Means BoW is: ' + str(bow_kmeans_sil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means BoW appears only slightly better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit K-Means\n",
    "tfidf_full_pred = KMeans(n_clusters=15, random_state=42).fit_predict(tfidf_train_out)\n",
    "\n",
    "# Check actual vs predicted\n",
    "pd.crosstab(Y_train, tfidf_full_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit Mini-Batch K-Means\n",
    "minibatchkmeans = MiniBatchKMeans(init='random', n_clusters=15, batch_size=1000)\n",
    "minibatchkmeans.fit(tfidf_train_out)\n",
    "\n",
    "predict_mini = minibatchkmeans.predict(tfidf_train_out)\n",
    "\n",
    "print('Comparing K-Means and Mini-Batch K-Means solutions:')\n",
    "print(pd.crosstab(predict_mini, tfidf_full_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-Batch runs much faster than a full K-Means but is does not have consistent results for many of the bloggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_kmeans_ari = metrics.adjusted_rand_score(Y_train, tfidf_full_pred)\n",
    "tfidf_kmeans_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), tfidf_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for K-Means tf-idf is: ' + str(tfidf_kmeans_ari))\n",
    "print('Silhouette score for K-Means tf-idf is: ' + str(tfidf_kmeans_sil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means tf-idf does not perform much better than BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean-Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "# Estimate bandwidth based on data\n",
    "bandwidth = estimate_bandwidth(bow_train_out.toarray(), quantile=0.5, n_samples=500, n_jobs=-1)\n",
    "\n",
    "# Initialize and fit model\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, min_bin_freq=10, n_jobs=3)\n",
    "ms.fit(bow_train_out.toarray())\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated Mean-Shift BoW clusters: {}\".format(n_clusters_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_full_pred = ms.predict(bow_train_out.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check actual vs predicted\n",
    "pd.crosstab(Y_train, bow_full_pred)\n",
    "\n",
    "bow_mean_shift_ari = metrics.adjusted_rand_score(Y_train, bow_full_pred)\n",
    "bow_mean_shift_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), bow_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Mean-Shift BoW is: ' + str(bow_kmeans_ari))\n",
    "print('Silhouette score for Mean-Shift BoW is: ' + str(bow_mean_shift_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate bandwidth based on data\n",
    "bandwidth = estimate_bandwidth(tfidf_train_out.toarray(), quantile=0.2, n_samples=500, n_jobs=3)\n",
    "\n",
    "# Initialize and fit model\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, min_bin_freq=10, n_jobs=3)\n",
    "ms.fit(tfidf_train_out.toarray())\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Coordinates of the cluster centers.\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated tf-idf Mean-Shift clusters: {}\".format(n_clusters_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_full_pred = ms.predict(tfidf_train_out.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check actual vs predicted\n",
    "pd.crosstab(Y_train, tfidf_full_pred)\n",
    "\n",
    "tfidf_mean_shift_ari = metrics.adjusted_rand_score(Y_train, tfidf_full_pred)\n",
    "tfidf_mean_shift_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), tfidf_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Mean-Shift tf-idf is: ' + str(tfidf_kmeans_ari))\n",
    "print('Silhouette score for Mean-Shift tf-idf is: ' + str(tfidf_kmeans_sil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Declare and fit the model\n",
    "sc = SpectralClustering(n_clusters=15)\n",
    "sc.fit(bow_train_out)\n",
    "\n",
    "#Predict clusters\n",
    "bow_full_pred = sc.fit_predict(bow_train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check actual vs predicted\n",
    "print(pd.crosstab(Y_train,bow_full_pred))\n",
    "\n",
    "bow_sc_ari = metrics.adjusted_rand_score(Y_train, bow_full_pred)\n",
    "bow_sc_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), bow_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Spectral Clustering BoW is: ' + str(bow_sc_ari))\n",
    "print('Silhouette score for Spectral Clustering BoW is: ' + str(bow_sc_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and fit the model\n",
    "sc = SpectralClustering(n_clusters=15)\n",
    "sc.fit(tfidf_train_out)\n",
    "\n",
    "#Predict clusters\n",
    "tfidf_full_pred = sc.fit_predict(tfidf_train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check actual vs predicted\n",
    "print(pd.crosstab(Y_train,tfidf_full_pred))\n",
    "\n",
    "tfidf_sc_ari = metrics.adjusted_rand_score(Y_train, tfidf_full_pred)\n",
    "tfidf_sc_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), tfidf_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Spectral Clustering tf-idf is: ' + str(tfidf_sc_ari))\n",
    "print('Silhouette score for Spectral Clustering tf-idf is: ' + str(tfidf_sc_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
