{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Blog Author Identification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 681284 total blog entries.\n"
     ]
    }
   ],
   "source": [
    "df0 = pd.read_csv('../data/blogtext.csv', delimiter=',',usecols=['id','topic','date','text'])\n",
    "df0.dataframeName = 'blogtext.csv'\n",
    "nRow, nCol = df0.shape\n",
    "print(f'There are {nRow} total blog entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.drop_duplicates(subset=\"text\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove blogs using non-English months in their date fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_strings = df0['date'].str.title()\n",
    "english_month = (date_strings.str.contains(',January,')) | (date_strings.str.contains(',February,')) | \\\n",
    "               (date_strings.str.contains(',March,')) | (date_strings.str.contains(',April,')) | \\\n",
    "               (date_strings.str.contains(',May,')) | (date_strings.str.contains(',June,')) | \\\n",
    "               (date_strings.str.contains(',July,')) | (date_strings.str.contains(',August,')) | \\\n",
    "               (date_strings.str.contains(',September,')) | (date_strings.str.contains(',October,')) | \\\n",
    "               (date_strings.str.contains(',November,')) | (date_strings.str.contains(',December,'))\n",
    "df = df0.drop(df0[~english_month].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering for English months, there are 604518 remaining blog entries.\n"
     ]
    }
   ],
   "source": [
    "df['datetime'] = pd.to_datetime(df['date'].str.title(), format='%d,%B,%Y')\n",
    "df = df.drop(columns=['date'])\n",
    "nRow, nCol = df.shape\n",
    "print(f'After filtering for English months, there are {nRow} remaining blog entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter blog entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of posts by author and topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_count = df.groupby('id').size()\n",
    "df['post_count'] = [ post_count[id] for id in df['id'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_count = df.groupby('topic').size()\n",
    "df['topic_count'] = [ topic_count[topic] for topic in df['topic'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most heavily posted topic is 'Student' so focus on those posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "11762        20\n",
       "48923       126\n",
       "71075         3\n",
       "105748       53\n",
       "106160       18\n",
       "114645      213\n",
       "216553       34\n",
       "216833      221\n",
       "278367        4\n",
       "298924      179\n",
       "420079       72\n",
       "424159       60\n",
       "445263       45\n",
       "452696       21\n",
       "466858       25\n",
       "472101       58\n",
       "477017       91\n",
       "479019     1001\n",
       "491348       26\n",
       "495541      306\n",
       "498684       69\n",
       "514171        4\n",
       "514483       22\n",
       "522409       82\n",
       "531918       23\n",
       "534904      113\n",
       "539545        8\n",
       "550590      180\n",
       "567598       20\n",
       "577518       30\n",
       "           ... \n",
       "4315396       2\n",
       "4316701       3\n",
       "4316835       1\n",
       "4317094       3\n",
       "4317294       3\n",
       "4317829       4\n",
       "4317864       3\n",
       "4317978       3\n",
       "4318162       3\n",
       "4319396       4\n",
       "4319763       2\n",
       "4320317       1\n",
       "4320557       7\n",
       "4320585       2\n",
       "4321212       3\n",
       "4321513       2\n",
       "4322723       4\n",
       "4323050       2\n",
       "4323690       2\n",
       "4325889      15\n",
       "4326228       8\n",
       "4329299       2\n",
       "4330295       2\n",
       "4330562       2\n",
       "4330772       3\n",
       "4331320       6\n",
       "4333070       1\n",
       "4335412       2\n",
       "4336267       6\n",
       "4337133       2\n",
       "Length: 5003, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['topic'] == 'Student']\n",
    "df.groupby('id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only authors with at least 500 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['post_count'] >= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "479019     1001\n",
       "642604      545\n",
       "780903     1337\n",
       "925742      542\n",
       "944569     1250\n",
       "955372     1749\n",
       "988941     1534\n",
       "1000866     770\n",
       "1119650     730\n",
       "1157144    1067\n",
       "1784456    1829\n",
       "1889734    1013\n",
       "1999563     623\n",
       "2297959     665\n",
       "3667467     646\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('id').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15301"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 15 remaining authors with a total of 15,301 posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['topic','datetime','post_count','topic_count'])\n",
    "df = df.reset_index(drop=True)\n",
    "#df.to_csv('reduced_blog_corpus.csv')\n",
    "\n",
    "del df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>988941</td>\n",
       "      <td>No one has joined yet, because I've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>988941</td>\n",
       "      <td>This is a group blog for, er, a gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>988941</td>\n",
       "      <td>About the  urlLink snooboo.com Foru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>988941</td>\n",
       "      <td>No the goverment won't increase pay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>988941</td>\n",
       "      <td>Aaaaaahhhhh, parents evening. My da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  988941             No one has joined yet, because I've...\n",
       "1  988941             This is a group blog for, er, a gro...\n",
       "2  988941             About the  urlLink snooboo.com Foru...\n",
       "3  988941             No the goverment won't increase pay...\n",
       "4  988941             Aaaaaahhhhh, parents evening. My da..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training/test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df['text'],df['id'], test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process posts with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Get spaCy stopwords\n",
    "nlp = spacy.load('c:/users/yfsta/anaconda3/lib/site-packages/en_core_web_lg/en_core_web_lg-2.1.0')\n",
    "stop_words = list(spacy.lang.en.stop_words.STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize English parser\n",
    "parser = English()\n",
    "\n",
    "# Create spaCy tokenizer\n",
    "def spacy_tokenizer(sentence):\n",
    "    \n",
    "    # Create tokens object from parser\n",
    "    tokens = nlp(sentence)\n",
    "#    tokens = parser(sentence)\n",
    "\n",
    "    # Remove words not included in NLP vocab list (oov = out of vocabulary)\n",
    "    tokens = [ t for t in tokens if t.is_oov is False ]\n",
    "    \n",
    "    # Exclusion list\n",
    "    exclusion_list = list(string.punctuation)\n",
    "    exclusion_list.extend(list(stop_words))\n",
    "    \n",
    "    # Lemmatize, convert to lowercase and remove extra spaces\n",
    "    tokens = [ w.lemma_.lower().strip() for w in tokens if w.lemma_ not in exclusion_list ]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Get spaCy stopwords\n",
    "nlp = spacy.load('c:/users/yfsta/anaconda3/lib/site-packages/en_core_web_lg/en_core_web_lg-2.1.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train_out = bow_vector.fit_transform(X_train)\n",
    "bow_test_out = bow_vector.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the BoW training set are: (11475, 31178)\n",
      "The dimensions of the BoW test set are: (3826, 19218)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of the BoW training set are: ' + str(bow_train_out.shape))\n",
    "print('The dimensions of the BoW test set are: ' + str(bow_test_out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "bow_train_out = normalize(bow_train_out)\n",
    "bow_test_out = normalize(bow_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_out = tfidf_vector.fit_transform(X_train)\n",
    "tfidf_test_out = tfidf_vector.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the tf-idf training set are: (11475, 31178)\n",
      "The dimensions of the tf-idf test set are: (3826, 19218)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of the tf-idf training set are: ' + str(tfidf_train_out.shape))\n",
    "print('The dimensions of the tf-idf test set are: ' + str(tfidf_test_out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_out = normalize(tfidf_train_out)\n",
    "tfidf_test_out = normalize(tfidf_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance of BoW training set captured by all components: 64.91124307080909\n"
     ]
    }
   ],
   "source": [
    "bow_svd = TruncatedSVD(300)\n",
    "bow_train_lsa = bow_svd.fit_transform(bow_train_out)\n",
    "\n",
    "variance_explained = bow_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance of BoW training set captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance of BoW test captured by all components: 61.73356435235304\n"
     ]
    }
   ],
   "source": [
    "bow_svd = TruncatedSVD(200)\n",
    "bow_test_lsa = bow_svd.fit_transform(bow_test_out)\n",
    "\n",
    "variance_explained=bow_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance of BoW test captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance tf-idf training captured by all components: 59.20365463323159\n"
     ]
    }
   ],
   "source": [
    "tfidf_svd= TruncatedSVD(1200)\n",
    "tfidf_train_lsa = tfidf_svd.fit_transform(tfidf_train_out)\n",
    "\n",
    "variance_explained=tfidf_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance tf-idf training captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance tf-idf test captured by all components: 60.41813557655089\n"
     ]
    }
   ],
   "source": [
    "tfidf_svd= TruncatedSVD(800)\n",
    "tfidf_test_lsa = tfidf_svd.fit_transform(tfidf_test_out)\n",
    "\n",
    "variance_explained=tfidf_svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance tf-idf test captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479019</th>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>105</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642604</th>\n",
       "      <td>14</td>\n",
       "      <td>115</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780903</th>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>126</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925742</th>\n",
       "      <td>5</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944569</th>\n",
       "      <td>45</td>\n",
       "      <td>136</td>\n",
       "      <td>46</td>\n",
       "      <td>31</td>\n",
       "      <td>82</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>83</td>\n",
       "      <td>47</td>\n",
       "      <td>174</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955372</th>\n",
       "      <td>146</td>\n",
       "      <td>268</td>\n",
       "      <td>119</td>\n",
       "      <td>134</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>216</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988941</th>\n",
       "      <td>165</td>\n",
       "      <td>131</td>\n",
       "      <td>97</td>\n",
       "      <td>209</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>98</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000866</th>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>190</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119650</th>\n",
       "      <td>3</td>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157144</th>\n",
       "      <td>53</td>\n",
       "      <td>107</td>\n",
       "      <td>65</td>\n",
       "      <td>44</td>\n",
       "      <td>71</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784456</th>\n",
       "      <td>93</td>\n",
       "      <td>105</td>\n",
       "      <td>54</td>\n",
       "      <td>282</td>\n",
       "      <td>85</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>120</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889734</th>\n",
       "      <td>32</td>\n",
       "      <td>105</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>140</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999563</th>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>117</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>49</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297959</th>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "      <td>39</td>\n",
       "      <td>94</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667467</th>\n",
       "      <td>33</td>\n",
       "      <td>110</td>\n",
       "      <td>19</td>\n",
       "      <td>103</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0    1    2    3    4   5   6    7   8   9    10  11   12   13   14\n",
       "id                                                                           \n",
       "479019    21   76   18   31  105  79   0  109   4   2   34   0  129   81   80\n",
       "642604    14  115   15   24   58  30   0   54   2   0   14   0   29   44   31\n",
       "780903    40   47   47   26  310   3   0  269   1   0    4   0   15  126  108\n",
       "925742     5   73   16    9   36   8  21   88   0   4    1   0    3  101   12\n",
       "944569    45  136   46   31   82  79   0  136   3   0   22  83   47  174   49\n",
       "955372   146  268  119  134   47  56   0  117  12  26   15   2   34  216  129\n",
       "988941   165  131   97  209   62  18   0   79   6   0    1   0   15   98  239\n",
       "1000866   46   16   12  190   23  13   0   17   3   0   72   0   35   19  123\n",
       "1119650    3  104    8   16  125   7   0  107   2   0    2   0    0  124   40\n",
       "1157144   53  107   65   44   71  66   0  101   6   1   43   3   77   84  100\n",
       "1784456   93  105   54  282   85  43   0  110   2   0  255   0   83  120  159\n",
       "1889734   32  105   54   21  140  10   0  195   3   0    0   0    2  156   34\n",
       "1999563   13   28   19   32  117  16   0  109   5   1    7   6   19   49   67\n",
       "2297959   53   80   39   94   25   4   0   32   2   0    0   7    4   68   83\n",
       "3667467   33  110   19  103   14   0   0   45   0   0    1   0    0   58   96"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Initialize and fit K-Means\n",
    "bow_full_pred = KMeans(n_clusters=15, random_state=42).fit_predict(bow_train_out)\n",
    "\n",
    "# Check actual vs. predicted\n",
    "pd.crosstab(Y_train, bow_full_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing K-Means and Mini-Batch K-Means solutions:\n",
      "col_0   0    1    2     3     4    5   6     7   8   9    10  11   12   13   14\n",
      "row_0                                                                          \n",
      "0        0    0    0  1244     0    0   1     0   0   2    3   0    0    0  329\n",
      "1       43    0    0     0   248    0   2  1533   8   0    0   0   39  886    0\n",
      "2        0  734  216     0     0  121   1     0  19   2    0   0    0  576    0\n",
      "3      364    0  381     0     0   34  15    33  20  24    0   0  173   19    0\n",
      "4        0    0    0     0     0    0   0     0   0   0    1  99    7    0    1\n",
      "5        2   14   28     0     0    8   0     2   1   0    0   1    1   19    0\n",
      "6        0  753    0     0     0    1   0     0   1   0    0   0    0   17    0\n",
      "7        0    0    1     0     0    0   0     0   0   0    0   0    0    0    0\n",
      "8        0    0    0     0     0    0   0     0   0   0    0   0    0    0    1\n",
      "9        0    0    1     0     0    0   0     0   0   0    0   0    0    0    0\n",
      "10       0    0    0     0     0    0   0     0   0   0    0   1    0    0    0\n",
      "11     349    0    0     0  1052    0   2     0   0   5    0   0   53    0  993\n",
      "12       4    0    0     2     0    0   0     0   0   1  467   0   92    0   26\n",
      "13       0    0    0     0     0    0   0     0   0   0    0   0    0    1    0\n",
      "14       0    0    1     0     0  268   0     0   2   0    0   0  127    0    0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# Initialize and fit Mini-Batch K-Means\n",
    "minibatchkmeans = MiniBatchKMeans(init='random', n_clusters=15, batch_size=1000)\n",
    "minibatchkmeans.fit(bow_train_out)\n",
    "\n",
    "predict_mini = minibatchkmeans.predict(bow_train_out)\n",
    "\n",
    "# Check the Mini-Batch model against our earlier one\n",
    "print('Comparing K-Means and Mini-Batch K-Means solutions:')\n",
    "print(pd.crosstab(predict_mini, bow_full_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-Batch runs much faster than a full K-Means and for most bloggers, the majority of results are consistent. However, there are some exceptions that are split fairly evenly between a couple of buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI for K-Means BoW is: 0.0316406610846862\n",
      "Silhouette score for K-Means BoW is: -0.5963023830976139\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "    \n",
    "bow_kmeans_ari = metrics.adjusted_rand_score(Y_train, bow_full_pred)\n",
    "bow_kmeans_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), bow_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for K-Means BoW is: ' + str(bow_kmeans_ari))\n",
    "print('Silhouette score for K-Means BoW is: ' + str(bow_kmeans_sil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means BoW appears only slightly better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479019</th>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>107</td>\n",
       "      <td>94</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642604</th>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780903</th>\n",
       "      <td>206</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>161</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>368</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925742</th>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>106</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944569</th>\n",
       "      <td>191</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>199</td>\n",
       "      <td>147</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955372</th>\n",
       "      <td>444</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>343</td>\n",
       "      <td>103</td>\n",
       "      <td>192</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988941</th>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>150</td>\n",
       "      <td>33</td>\n",
       "      <td>342</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>80</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000866</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>217</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119650</th>\n",
       "      <td>73</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157144</th>\n",
       "      <td>249</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>154</td>\n",
       "      <td>79</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784456</th>\n",
       "      <td>282</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>143</td>\n",
       "      <td>88</td>\n",
       "      <td>414</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>168</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889734</th>\n",
       "      <td>194</td>\n",
       "      <td>4</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>111</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999563</th>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>103</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297959</th>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>20</td>\n",
       "      <td>142</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667467</th>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>131</td>\n",
       "      <td>34</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0   1    2   3   4   5    6    7    8   9    10   11  12   13   14\n",
       "id                                                                          \n",
       "479019   116   0   15   2   0   6  107   94  142   1    0    2  19   54  211\n",
       "642604    88   4    1   3   9  26  119   48   31   4    0    0   1   50   46\n",
       "780903   206   3   10   0   5   1   96  161   75   6  368    0   8   43   14\n",
       "925742    88   1    0   8   7   0  119  106   21   3    2    2   0   14    6\n",
       "944569   191  10    1  14   2  14  199  147   56  45    0  140  15   28   71\n",
       "955372   444  21    4  28   0  16  343  103  192  33    0   11   4   65   57\n",
       "988941   361   2    5  31  20  10  150   33  342  61    0    0  11   80   14\n",
       "1000866   60   1    0  11  31   0   20   12  137   1    0    0  22  217   57\n",
       "1119650   73  13    2   5   0   1  173  152   48  15    0    0   0   51    5\n",
       "1157144  249   5    2  14   4   4  154   79  142   2    0   17   5   31  113\n",
       "1784456  282  10    1   4  15   9  143   88  414  30    0    2  11  168  214\n",
       "1889734  194   4  196   0   0   1  167  111   33  18    1    0   2   21    4\n",
       "1999563   55   2    0   4  53   0   46  103   73   4    1   31   1   93   22\n",
       "2297959  150   4    0   7   1   5   92   20  142   5    0   23   4   37    1\n",
       "3667467  112   0   13   0   0  15  131   34  138   0    1    0   5   29    1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit K-Means\n",
    "tfidf_full_pred = KMeans(n_clusters=15, random_state=42).fit_predict(tfidf_train_out)\n",
    "\n",
    "# Check actual vs predicted\n",
    "pd.crosstab(Y_train, tfidf_full_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing K-Means and Mini-Batch K-Means solutions:\n",
      "col_0    0   1    2   3   4    5     6    7     8    9    10   11  12   13   14\n",
      "row_0                                                                          \n",
      "0         0   0    0   0   0    0     0    0     1    0    0    0   0    0    0\n",
      "1        38   0    3   3   5    0     1    9    32  207    0    0   6    0   10\n",
      "2        95   7   21  44  35  101  1956  314     0    4    0    0  27    0  121\n",
      "3        36   0    1   1   0    0    30    4     3    0    0    0   3    0   10\n",
      "4      2304   2  183  60  61    0     3  184   596    0    0    0  42    0  409\n",
      "5         0   0    0   0   0    0     0    0     0    0    1    0   0    0    0\n",
      "6        48   0    0   2  13    0    39   35    16   14    2    0   6    0    9\n",
      "7         0  69    0   5   1    0     0    1     4    0    0    0   0    1    2\n",
      "8        18   0    0   0   0    0     8    6     4    0    0    0   1    0    4\n",
      "9        24   1    0   4   6    0     4    7    10    2    0  228   0    1   21\n",
      "10       57   0    0   1   0    0    11    2     3    1    0    0   0    0    4\n",
      "11       24   0    0   0   0    0     3    2     1    0    0    0   0    0    0\n",
      "12       25   1    5   0   0    7     4   92    12    0  358    0   4    1    3\n",
      "13        0   0   37  11  26    0     0  635  1304    0   11    0  19  978  243\n",
      "14        0   0    0   0   0    0     0    0     0    0    1    0   0    0    0\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit Mini-Batch K-Means\n",
    "minibatchkmeans = MiniBatchKMeans(init='random', n_clusters=15, batch_size=1000)\n",
    "minibatchkmeans.fit(tfidf_train_out)\n",
    "\n",
    "predict_mini = minibatchkmeans.predict(tfidf_train_out)\n",
    "\n",
    "print('Comparing K-Means and Mini-Batch K-Means solutions:')\n",
    "print(pd.crosstab(predict_mini, tfidf_full_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini-Batch runs much faster than a full K-Means but is does not have consistent results for many of the bloggers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI for K-Means tf-idf is: 0.04224020946527432\n",
      "Silhouette score for K-Means tf-idf is: -0.49868350058777094\n"
     ]
    }
   ],
   "source": [
    "tfidf_kmeans_ari = metrics.adjusted_rand_score(Y_train, tfidf_full_pred)\n",
    "tfidf_kmeans_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), tfidf_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for K-Means tf-idf is: ' + str(tfidf_kmeans_ari))\n",
    "print('Silhouette score for K-Means tf-idf is: ' + str(tfidf_kmeans_sil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means tf-idf does not perform much better than BoW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean-Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated Mean-Shift BoW clusters: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "# Estimate bandwidth based on data\n",
    "bandwidth = estimate_bandwidth(bow_train_out.toarray(), quantile=0.5, n_samples=500, n_jobs=-1)\n",
    "\n",
    "# Initialize and fit model\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, min_bin_freq=10, n_jobs=3)\n",
    "ms.fit(bow_train_out.toarray())\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated Mean-Shift BoW clusters: {}\".format(n_clusters_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_full_pred = ms.predict(bow_train_out.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"<ipython-input-40-05171ada62d9>\"\u001b[0m, line \u001b[0;32m5\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    bow_mean_shift_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), bow_full_pred, metric='euclidean')\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\unsupervised.py\"\u001b[0m, line \u001b[0;32m117\u001b[0m, in \u001b[0;35msilhouette_score\u001b[0m\n    return np.mean(silhouette_samples(X, labels, metric=metric, **kwds))\n",
      "  File \u001b[0;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\unsupervised.py\"\u001b[0m, line \u001b[0;32m217\u001b[0m, in \u001b[0;35msilhouette_samples\u001b[0m\n    check_number_of_labels(len(le.classes_), n_samples)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\yfsta\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\unsupervised.py\"\u001b[1;36m, line \u001b[1;32m35\u001b[1;36m, in \u001b[1;35mcheck_number_of_labels\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"to n_samples - 1 (inclusive)\" % n_labels)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m\u001b[1;31m:\u001b[0m Number of labels is 1. Valid values are 2 to n_samples - 1 (inclusive)\n"
     ]
    }
   ],
   "source": [
    "# Check actual vs predicted\n",
    "pd.crosstab(Y_train, bow_full_pred)\n",
    "\n",
    "bow_mean_shift_ari = metrics.adjusted_rand_score(Y_train, bow_full_pred)\n",
    "bow_mean_shift_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), bow_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Mean-Shift BoW is: ' + str(bow_kmeans_ari))\n",
    "print('Silhouette score for Mean-Shift BoW is: ' + str(bow_mean_shift_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate bandwidth based on data\n",
    "bandwidth = estimate_bandwidth(tfidf_train_out.toarray(), quantile=0.2, n_samples=500, n_jobs=3)\n",
    "\n",
    "# Initialize and fit model\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, min_bin_freq=10, n_jobs=3)\n",
    "ms.fit(tfidf_train_out.toarray())\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Coordinates of the cluster centers.\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated tf-idf Mean-Shift clusters: {}\".format(n_clusters_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_full_pred = ms.predict(tfidf_train_out.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check actual vs predicted\n",
    "pd.crosstab(Y_train, tfidf_full_pred)\n",
    "\n",
    "tfidf_mean_shift_ari = metrics.adjusted_rand_score(Y_train, tfidf_full_pred)\n",
    "tfidf_mean_shift_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), tfidf_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Mean-Shift tf-idf is: ' + str(tfidf_kmeans_ari))\n",
    "print('Silhouette score for Mean-Shift tf-idf is: ' + str(tfidf_kmeans_sil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# Declare and fit the model\n",
    "sc = SpectralClustering(n_clusters=15)\n",
    "sc.fit(bow_train_out)\n",
    "\n",
    "#Predict clusters\n",
    "bow_full_pred = sc.fit_predict(bow_train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0     0    1   2   3   4    5    6   7    8    9    10   11  12  13   14\n",
      "id                                                                          \n",
      "479019    45   11  47  86   1   57  196  18   79   35    0   83  38  32   41\n",
      "642604   101   32   8  21   0   48  116  26    8   10    0   16  12  16   16\n",
      "780903    36   56  19   6   0   93  402  24  276   15    0   24   7  33    5\n",
      "925742    56   35   7   6   4   19  165  10   15   17    1    7  14  20    1\n",
      "944569   106  109  30  54   0   51  292  54   10   26  109    6  23  36   27\n",
      "955372   207  257  42  48  22  116  260  39   37  136    8   38  50  47   14\n",
      "988941   103  173  60  15   0  276  149  35   48   37    0  100  74  47    3\n",
      "1000866   10   34  65   9   0  165   38  43   16   38    0   18  41  20   72\n",
      "1119650   97   21  13   6   0   62  270   7    9   16    0   13   9  13    2\n",
      "1157144   75  108  52  60   1   81  198  59   24   29    4   22  25  31   52\n",
      "1784456   78  154  79  41   0  255  215  39   50   42    0   27  32  35  344\n",
      "1889734   72   96  27  13   0   56  325  16   34   17    0   21  21  54    0\n",
      "1999563   15   29  19  11   1   71  189   9   13   67   12   29  13   6    4\n",
      "2297959   50   51  38   3   0  109   56  24   19   41   17   38  19  25    1\n",
      "3667467  105   37  17   0   0  134   74  11   25   16    0   18  11  31    0\n",
      "ARI for Spectral Clustering BoW is: 0.0303612918209541\n",
      "Silhouette score for Spectral Clustering BoW is: -0.5432894274148073\n"
     ]
    }
   ],
   "source": [
    "# Check actual vs predicted\n",
    "print(pd.crosstab(Y_train,bow_full_pred))\n",
    "\n",
    "bow_sc_ari = metrics.adjusted_rand_score(Y_train, bow_full_pred)\n",
    "bow_sc_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), bow_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Spectral Clustering BoW is: ' + str(bow_sc_ari))\n",
    "print('Silhouette score for Spectral Clustering BoW is: ' + str(bow_sc_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and fit the model\n",
    "sc = SpectralClustering(n_clusters=15)\n",
    "sc.fit(tfidf_train_out)\n",
    "\n",
    "#Predict clusters\n",
    "tfidf_full_pred = sc.fit_predict(tfidf_train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0     0   1    2   3   4   5    6    7   8    9    10  11   12  13   14\n",
      "id                                                                         \n",
      "479019   124   0   46   1   0   0   58    2   0    2  168   1  285   3   79\n",
      "642604   190   0   26   0   0   4   86    0   0    0   47  20   24   5   28\n",
      "780903   273   0   52   0   0   3  155    0   0  427   13   0   47   9   17\n",
      "925742   136   0   16   4   0   1  101    1  21    4    9   0   49   4   31\n",
      "944569   338   0   56   0   5  11  188  129   0    0   80   7   23  60   36\n",
      "955372   625   0  163  27   3  21  151   11   0    3   60   7  102  40  108\n",
      "988941   370   0  280   0   4   2   41    0   0    0   17   6  300  69   31\n",
      "1000866   60   0   91   0   0   2   18    0   0    0   46   0  141   3  208\n",
      "1119650  204   0   45   0   0  13  215    0   0    0    6   0   28  16   11\n",
      "1157144  333   0  117   2   4   4   76   13   0    1  120   3   72   2   74\n",
      "1784456  337   0  532   0   1  11   84    0   0    1  246   9   55  45   70\n",
      "1889734  490   0   53   0   0   4  155    0   0    4    6   0   15  19    6\n",
      "1999563   66  12   39   1   0   3  105   28   0    1   26   0   89   5  113\n",
      "2297959  180   0  112   9   0   4   25   22   0    0    1   1   57   5   75\n",
      "3667467  233   0  122   0   0   0   47    0   0   10    0   8   47   1   11\n",
      "ARI for Spectral Clustering tf-idf is: 0.049555665448415345\n",
      "Silhouette score for Spectral Clustering tf-idf is: -0.7196205994760377\n"
     ]
    }
   ],
   "source": [
    "# Check actual vs predicted\n",
    "print(pd.crosstab(Y_train,tfidf_full_pred))\n",
    "\n",
    "tfidf_sc_ari = metrics.adjusted_rand_score(Y_train, tfidf_full_pred)\n",
    "tfidf_sc_sil = metrics.silhouette_score(Y_train.values.reshape(-1,1), tfidf_full_pred, metric='euclidean')\n",
    "\n",
    "print('ARI for Spectral Clustering tf-idf is: ' + str(tfidf_sc_ari))\n",
    "print('Silhouette score for Spectral Clustering tf-idf is: ' + str(tfidf_sc_sil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
